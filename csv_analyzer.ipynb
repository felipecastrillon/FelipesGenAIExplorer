{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2mdBNzaq8XW2",
   "metadata": {
    "id": "2mdBNzaq8XW2"
   },
   "source": [
    "# CSV Analyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea575b2-3a61-43ae-9454-e515d4d377cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generative Question and Answer (QnA) analyzer of csv files. The focus is on small csv files (100s or 1000s of rows) where traditionally users are doing analysis on a spreadsheet but want a more interactive way to do their analysis. \n",
    "\n",
    "Today you can drop a csv on your LLM of choice and can get answers to some complex questions that focus on language summarization tasks like topic categorization, sentiment analysis, sampling of data. Where LLM usually fail is in doing computation of your data i.e. filtering, aggregation, counts etc. \n",
    "\n",
    "In order to overcome this drawback we are taking advantage of an agentic approach while giving it access to a pandas runner. This allows the agent the ability to run computations via pandas commands. The agent will use a reAct framework to be able to think through the problem and access the pandas dataframe only when necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gncZnt8YwkTS",
   "metadata": {
    "id": "gncZnt8YwkTS"
   },
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nwtoa1WKsSlSj4VrqdEY8LId",
   "metadata": {
    "id": "Nwtoa1WKsSlSj4VrqdEY8LId",
    "tags": []
   },
   "source": [
    "Install the Langchain packages: Open a terminal window and enter the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qsskCvGUcbn34hNAWisBS4Uk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 46113,
     "status": "ok",
     "timestamp": 1730319297839,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "qsskCvGUcbn34hNAWisBS4Uk",
    "outputId": "fc4d3234-5fe5-44ea-8dba-f70683408d49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade google-cloud-aiplatform\n",
    "!pip install --quiet vertexai\n",
    "!pip install --quiet langchain-google-genai\n",
    "!pip install --quiet langchain\n",
    "!pip install --quiet langchain-experimental\n",
    "!pip install --no-deps --quiet langchain-google-vertexai \n",
    "!pip install --quiet panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9d81f-d79a-4bb1-bf65-f7f51245daa6",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fd443a-f7fd-432d-a909-10e3513bcd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = 'felipe-sandbox-354619' # replace with project ID\n",
    "BUCKET = PROJECT + \"-bucket\" # make sure this bucket exists\n",
    "CSV_FILE_SMALL = \"files/customer-comments-small.csv\" \n",
    "CSV_FILE_MEDIUM = \"files/customer-comments.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce2df3-64a3-4f57-a9fb-1c8a1dfcc83b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Colab setup if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af014e5-b39e-4a93-9e0a-628717e83c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eefb1f-89cb-4231-8f57-75888dafa34c",
   "metadata": {},
   "source": [
    "## Naive Approach: Ask LLM Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e775bc-7b7a-4831-a9a2-f683eabf26b2",
   "metadata": {},
   "source": [
    "LLMs are notoriously bad at counting and providing any analytics without any proper guidance. Let's look at an example for a file that has 100 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd31854f-6248-4865-b2e9-f5f0707e6d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "llm = ChatVertexAI(model=\"gemini-1.5-pro-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0511b6a6-d1a1-450c-9224-ddb0d161bf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_string(filename):\n",
    "  \"\"\"\n",
    "  Reads a CSV file and returns its contents as a string.\n",
    "\n",
    "  Args:\n",
    "    filename: The path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "    A string containing the CSV data.\n",
    "  \"\"\"\n",
    "\n",
    "  df = pd.read_csv(CSV_FILE_MEDIUM).drop(\"index\", axis=1)\n",
    "  df =df.reset_index(drop=True)\n",
    "  return df.to_string(index=False)\n",
    "    \n",
    "    \n",
    "  with open(filename, 'r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = \"\"\n",
    "    for row in reader:\n",
    "      data += ','.join(row) + '\\n'  # Join row elements with commas and add newline\n",
    "    return data\n",
    "\n",
    "# Example usage \n",
    "csv_string_small = csv_to_string(CSV_FILE_SMALL)\n",
    "csv_string = csv_to_string(CSV_FILE_MEDIUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1e7ac30-9e1e-461d-ac7b-85f3611af85f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 75 rows of comment/country pairs in the data you provided.  Each line containing a comment and a country constitutes one row.\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(csv_string + \"\\n how many rows in the file?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4243f0b-d898-4d0e-a7a7-6a0a4d591f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 rows from the US in the provided data.  I counted them manually.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/quotas#error-code-429 for more details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's count the rows where the country is Canada:\n",
      "\n",
      "1.  I have a question about my order.  Canada\n",
      "2.  The customer support agent was very helpful.  Canada\n",
      "3.  I couldn't find the information I needed.  Canada\n",
      "4.  The delivery was late.  Canada\n",
      "5.  I had a problem with the online payment system.  Canada\n",
      "6.  I'm having trouble with the product setup.  Canada\n",
      "7.  I'm very happy with the service!  Canada\n",
      "8.  I need to return an item.  Canada\n",
      "9.  I would recommend this company to others.  Canada\n",
      "10. I received the wrong item.  Canada\n",
      "11. The product is not as described.  Canada\n",
      "12. The delivery was late.  Canada\n",
      "13. I'm not satisfied with the product quality.  Canada\n",
      "14. I couldn't find the information I needed.  Canada\n",
      "15. I'm very happy with the service!  Canada\n",
      "16. The product arrived damaged.  Canada\n",
      "17. I have a question about my order.  Canada\n",
      "18. The delivery was late.  Canada\n",
      "19. The customer support agent was very helpful.  Canada\n",
      "20. I couldn't find the information I needed.  Canada\n",
      "21. The website is easy to use.  Canada\n",
      "22. I would recommend this company to others.  Canada\n",
      "23. I have a question about my order.  Canada\n",
      "24. The customer support agent was very helpful.  Canada\n",
      "25. I had a problem with the online payment system.  Canada\n",
      "26. I' received the wrong item. Canada\n",
      "27. The product arrived damaged. Canada\n",
      "28. The delivery was late. Canada\n",
      "29. I'm not satisfied with the product quality. Canada\n",
      "30. The website is easy to use. Canada\n",
      "31. The price is too high. Canada\n",
      "32. I would recommend this company to others. Canada\n",
      "\n",
      "There are 32 rows from Canada.\n",
      "\n",
      "Let's count the rows where the country is Mexico:\n",
      "\n",
      "1. I'm very happy with the service!  Mexico\n",
      "2. I'm not satisfied with the product quality.  Mexico\n",
      "3. The price is too high.  Mexico\n",
      "4. The product is not as described.  Mexico\n",
      "5. The product arrived damaged.  Mexico\n",
      "6. The customer support agent was very helpful.  Mexico\n",
      "7. The website is easy to use.  Mexico\n",
      "8. I had a problem with the online payment system.  Mexico\n",
      "9. I'm having trouble with the product setup.  Mexico\n",
      "10. I have a question about my order.  Mexico\n",
      "11. I need to return an item.  Mexico\n",
      "12. I received the wrong item.  Mexico\n",
      "13. I'm very happy with the service!  Mexico\n",
      "14. I'm not satisfied with the product quality.  Mexico\n",
      "15. The price is too high.  Mexico\n",
      "16. I had a problem with the online payment system.  Mexico\n",
      "17. The product is not as described.  Mexico\n",
      "18. I have a question about my order.  Mexico\n",
      "19. I need to return an item.  Mexico\n",
      "20. I couldn't find the information I needed.  Mexico\n",
      "21. I'm very happy with the service!  Mexico\n",
      "22. I'm not satisfied with the product quality.  Mexico\n",
      "23. The product arrived damaged.  Mexico\n",
      "24. The delivery was late.  Mexico\n",
      "25. I would recommend this company to others.  Mexico\n",
      "26. I received the wrong item.  Mexico\n",
      "27. The product is not as described.  Mexico\n",
      "\n",
      "There are 27 rows from Mexico.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(csv_string + \"\\n how many rows from the US?\").content)\n",
    "print(llm.invoke(csv_string + \"\\n how many rows from Canada?\").content)\n",
    "print(llm.invoke(csv_string + \"\\n how many rows from Mexico?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50d68e76-c286-44fe-96f1-5ff324a04de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_FILE_MEDIUM)\n",
    "print(len(df[df['country'].str.contains('US')]))\n",
    "print(len(df[df['country'].str.contains('Canada')]))\n",
    "print(len(df[df['country'].str.contains('Mexico')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "885b83ce-46c7-41ce-bd38-c57d3262b98e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a breakdown of the comments into five categories and their counts:\n",
      "\n",
      "1. **Shipping Issues (17):**\n",
      "    * The product arrived damaged. (6)\n",
      "    * The delivery was late. (5)\n",
      "    * I received the wrong item. (6)\n",
      "\n",
      "2. **Product Issues (17):**\n",
      "    * I'm not satisfied with the product quality. (6)\n",
      "    * The product is not as described. (6)\n",
      "    * I'm having trouble with the product setup. (5)\n",
      "\n",
      "3. **Service Issues (12):**\n",
      "    * I have a question about my order. (6)\n",
      "    * I couldn't find the information I needed. (6)\n",
      "\n",
      "\n",
      "4. **Returns (6):**\n",
      "    * I need to return an item. (6)\n",
      "\n",
      "5. **Positive Feedback/Other (12):**\n",
      "    * I'm very happy with the service! (6)\n",
      "    * I would recommend this company to others. (6)\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(csv_string + \"\\n can you categorize into 5 categories and count the number of rows for each category?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3EZsamn67y6J",
   "metadata": {
    "id": "3EZsamn67y6J"
   },
   "source": [
    "## Langchain Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f585656-6fed-4696-bc03-e3fbe840ca42",
   "metadata": {},
   "source": [
    "In order to ovecome some of these obstacles we want to use a LLM method called ReAct where the LLM can think before answering. ReAct works by having a certain number of Tools that can help solve a task. The LLM will then think about each step carefully to come up with a set of steps to solve the problem and also determine if one of the Tools will be needed to solve the taks. Tools can be python code, API calls, or any other instruction that is needed to complete the task. This allows a more robust process to solve difficult answers and leverage grounded steps within the Tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aZAoXfB8z4uIoOWQgYDPEvj5",
   "metadata": {
    "id": "aZAoXfB8z4uIoOWQgYDPEvj5",
    "tags": []
   },
   "source": [
    "### Create Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6adc58-396f-4dae-84d5-134cdf74fc44",
   "metadata": {},
   "source": [
    "create a tool that loads csv file into a pandas dataframe and run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dFDFBiEF-cX",
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1730321794859,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "2dFDFBiEF-cX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import tool\n",
    "from io import StringIO\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "@tool(\"pandas_calculator\", return_direct=False)\n",
    "def pandas_calculator(dictionary:str):\n",
    "    \"\"\"\n",
    "    Evaluates an expression on a Pandas DataFrame and returns the result.\n",
    "    Inputs include an expression expr and a file path csv_file_path\n",
    "    Inputs should be in format {\\\"expr\\\": str, \\\"csv_file_path\\\": str}\n",
    "    \n",
    "    Always favor df.contains functions instead of precise functions using equality operators\n",
    "    \"\"\"\n",
    "    print (\"-\" + dictionary + \"-\")\n",
    "    dictionary = json.loads(dictionary)\n",
    "    csv_file_path = dictionary[\"csv_file_path\"]\n",
    "    expr = dictionary[\"expr\"]\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(df)\n",
    "        # evaluate expr on the pandas dataframe\n",
    "        result = eval(expr)\n",
    "        # return the result\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Could not load data or evaluate expression. {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bcfd5a-168f-4b5a-8270-f92ac151b626",
   "metadata": {},
   "source": [
    "Tool to summarize the file so that LLM can generate correct SQLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db6506fb-b152-456d-b4d9-724e9b42164f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-{\"csv_input_file\":\"files/customer-comments-small.csv\"}-\n",
      "first few rows of data: \n",
      "   index                                       comment country\n",
      "0      1                  The product arrived damaged.      US\n",
      "1      2              I'm very happy with the service!  Mexico\n",
      "2      3             I have a question about my order.  Canada\n",
      "3      4                        The delivery was late.      US\n",
      "4      5  The customer support agent was very helpful.  Canada\n",
      "\n",
      "information on the data:            index                       comment country\n",
      "count   10.00000                            10      10\n",
      "unique       NaN                            10       3\n",
      "top          NaN  The product arrived damaged.      US\n",
      "freq         NaN                             1       4\n",
      "mean     5.50000                           NaN     NaN\n",
      "std      3.02765                           NaN     NaN\n",
      "min      1.00000                           NaN     NaN\n",
      "25%      3.25000                           NaN     NaN\n",
      "50%      5.50000                           NaN     NaN\n",
      "75%      7.75000                           NaN     NaN\n",
      "max     10.00000                           NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "@tool(\"csv_summary_statistics\", return_direct=False)\n",
    "def csv_summary_statistics(dictionary:str):\n",
    "    \"\"\"\n",
    "    Gets summary statistics on the csv to understand the data\n",
    "    Before running pandas calculator please run the statistics first\n",
    "    Inputs should be in format: {\\\"csv_input_file\\\": str}\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"-\" + dictionary + \"-\")\n",
    "    dictionary = json.loads(dictionary)\n",
    "    input_path = dictionary[\"csv_input_file\"]\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "        # evaluate expr on the pandas dataframe\n",
    "        result = \"first few rows of data: \\n\" + df.head().to_string() + \"\\n\\n\"\n",
    "        result += \"information on the data: \" + df.describe(include='all').to_string()\n",
    "        #print(df.info())\n",
    "        # return the result\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Could not load data or evaluate expression. {e}\"\n",
    "    \n",
    "test_path = \"{\\\"csv_input_file\\\":\\\"\" + CSV_FILE_SMALL + \"\\\"}\"\n",
    "print(csv_summary_statistics(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ceeb5-88b0-4484-a4fb-63929b916c23",
   "metadata": {},
   "source": [
    "Tool to fill in any columns that do not exist (being tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48fb4b7e-c655-4415-8442-06abeff4cdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/quotas#error-code-429 for more details..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/quotas#error-code-429 for more details..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/quotas#error-code-429 for more details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewrite prompt :For this specific row, choose the sentiment analysis category that applies: [Positive, Negative].\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'files/modified_file_name.csv'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "@tool(\"generate_column\", return_direct=False)\n",
    "def generate_column(dictionary:str):\n",
    "    \"\"\"\n",
    "    For some tasks the column that is needed does not exist and needs to be generated via LLM\n",
    "    This function will loop through each row and fill in the column via some prompt instructions\n",
    "    Inputs should be in format {\\\"csv_input_file\\\": str, \"prompt_instructions\":str, \"column_name\":str}\n",
    "    \n",
    "    csv_input_file: is the file to be loaded\n",
    "    column_name: is the name of the new column that will be generated\n",
    "    prompt_instructions: is the prompt used by the LLM to generate the column. This will be applied to \n",
    "    each row based on function: df[column_name] = df.apply(lambda x: llm.generate(prompt_instructions + \"\\n row context\" + x + \"\\n result:\\n\"))\n",
    "    \"\"\"\n",
    "    \n",
    "    llm = ChatVertexAI(model=\"gemini-1.5-pro-002\")\n",
    "    \n",
    "    dictionary = json.loads(dictionary)\n",
    "    input_path = dictionary[\"csv_input_file\"]\n",
    "    prompt_instructions = dictionary[\"prompt_instructions\"]\n",
    "    column_name = dictionary[\"column_name\"]\n",
    "    \n",
    "    prompt_prefix = \"\"\"Follow the instructions, be to the point and do not do anything outside of the\n",
    "                    \"instructions. \n",
    "                    \n",
    "                    INSTRUCTIONS:\n",
    "                    answer should be concise\n",
    "                    answer should not have a newline character\n",
    "                    answer should not have any special characters\n",
    "                    \n",
    "                    \"\"\"\n",
    "\n",
    "    better_prompt_instructions = llm.invoke(f\"\"\"can you help me rewrite this prompt to a better more specific prompt\n",
    "                                            Each of these instructions will be applied to \"this row\" please specify that\n",
    "                                            if the answer needs be categorical please come up with the proper categories in brackets: i.e. [cat1, cat2]\n",
    "                                        \n",
    "                                            \n",
    "                                            EXAMPLE: \n",
    "                                            \n",
    "                                            PROMPT: does this refer to a cat or a dog\n",
    "                                            NEW PROMPT: for this specific row does this refer to one of the following categories [cat,dog] pick one as your answer\n",
    "                                            \n",
    "                                            Please only focus on the task of writing one specific prompt, do not provide any additional information or explanation\n",
    "                                            \n",
    "                                            PROMPT:\n",
    "                                            {prompt_instructions}\n",
    "                                            \n",
    "                                            NEW PROMPT:\"\"\").content\n",
    "    \n",
    "    print(\"rewrite prompt :\" + better_prompt_instructions)\n",
    "    \n",
    "    def generate_sentiment(row, prompt_instructions):\n",
    "        prompt = f\"{prompt_prefix} \\nINSTRUCTIONS: {better_prompt_instructions} \\nCONTEXT ROW: {row.to_string()} \\nANSWER:\"\n",
    "        #print(\"final prompt \" + prompt)\n",
    "        return llm.invoke(prompt).content  # Pass the message object to generate()\n",
    "        \n",
    "    df = pd.read_csv(input_path)\n",
    "    df[column_name] = df.apply(lambda x:generate_sentiment(x, prompt_instructions).strip(), axis=1)\n",
    "    filename = 'files/modified_file_name.csv'\n",
    "    df.to_csv(filename, index=False) \n",
    "\n",
    "    return filename\n",
    "\n",
    "data_test = '{\\\"csv_input_file\\\":\\\"'+CSV_FILE_SMALL+'\\\", \\\"prompt_instructions\\\":\\\"pick positive or negative sentiment analysis for each row\\\", \\\"column_name\\\":\\\"sentiment\\\"}'\n",
    "generate_column(data_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e7b7a4-bd5e-4c04-b310-272bf776269a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_string = \"\"\"\n",
    "Assistant is a large language model trained by OpenAI.\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "TOOLS:\n",
    "\n",
    "------\n",
    "\n",
    "Assistant has access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "```\n",
    "\n",
    "Sometimes if the questions does not require a tool you can answer like this:\n",
    "\n",
    "```\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "```\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "New input: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "n7YCgEQM74Ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1730321798695,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "n7YCgEQM74Ac",
    "outputId": "8a20b6d9-d9ab-4c39-edf1-69c024e49963",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_4224/286323868.py:12: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_history = ConversationBufferWindowMemory(k=10)\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.memory import ConversationBufferWindowMemory, ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-1.5-pro-002\", temperature=0)\n",
    "prompt = PromptTemplate.from_template(prompt_string)\n",
    "#prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "chat_history = ConversationBufferWindowMemory(k=10)\n",
    "\n",
    "agent = create_react_agent(llm, [pandas_calculator,csv_summary_statistics,generate_column], prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent,\n",
    "                               tools=[pandas_calculator,csv_summary_statistics,generate_column],\n",
    "                               verbose=True, handle_parsing_errors=True,\n",
    "                               max_iterations=5, return_intermediate_steps=True)\n",
    "\n",
    "def append_chat_history(input, response):\n",
    "    chat_history.save_context({\"input\": input}, {\"output\": response})\n",
    "\n",
    "def tuples_to_string(list_of_tuples):\n",
    "  \"\"\"Converts a list of tuples to a string representation.\"\"\"\n",
    "\n",
    "  # If the list is empty, return an empty string\n",
    "  if not list_of_tuples:\n",
    "    return \"\"\n",
    "\n",
    "  # Join the tuples with a newline character\n",
    "  string = \"\\n\".join([str(tup) for tup in list_of_tuples])\n",
    "  return string\n",
    "    \n",
    "def invoke(input):\n",
    "    if (input):\n",
    "        #print(\"input: \" + str(input))\n",
    "        msg = {\n",
    "            \"input\": input,\n",
    "            \"chat_history\": chat_history.load_memory_variables({}),\n",
    "        }\n",
    "        #print(f\"Input: {msg}\")\n",
    "\n",
    "        response = agent_executor.invoke(msg)\n",
    "        response[\"output\"] = response[\"output\"].split(\"\\n\")[0]\n",
    "        #print(f\"Response: {response}\")\n",
    "\n",
    "        if not response[\"intermediate_steps\"]:\n",
    "            response[\"intermediate_steps\"] = [\"NaN\"]\n",
    "        \n",
    "        print(response[\"intermediate_steps\"])\n",
    "        output_string = \"intermediate steps: \" + tuples_to_string(response[\"intermediate_steps\"]) + \" | response: \" + response[\"output\"]\n",
    "        append_chat_history(response[\"input\"], output_string)\n",
    "        #print(f\"History: {chat_history.load_memory_variables({})}\")\n",
    "\n",
    "        return response[\"output\"]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c0fadf-17ae-4072-b162-74150b8c8563",
   "metadata": {},
   "source": [
    "### Try Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d49d24b-2e63-45d2-ad00-ddcd142e8203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: Hi there! How can I help you today?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['NaN']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eVrNIXm9MHtm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3492,
     "status": "ok",
     "timestamp": 1730321808028,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "eVrNIXm9MHtm",
    "outputId": "caf99249-d308-4d8c-81fd-cba6a9fb7348",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use the pandas_calculator tool to count the number of rows where the country is US. First I will check the summary statistics of the csv to understand the data better.\n",
      "Action: csv_summary_statistics\n",
      "Action Input: {\"csv_input_file\": \"files/customer-comments-small.csv\"}\u001b[0m-{\"csv_input_file\": \"files/customer-comments-small.csv\"}-\n",
      "\u001b[33;1m\u001b[1;3mfirst few rows of data: \n",
      "   index                                       comment country\n",
      "0      1                  The product arrived damaged.      US\n",
      "1      2              I'm very happy with the service!  Mexico\n",
      "2      3             I have a question about my order.  Canada\n",
      "3      4                        The delivery was late.      US\n",
      "4      5  The customer support agent was very helpful.  Canada\n",
      "\n",
      "information on the data:            index                       comment country\n",
      "count   10.00000                            10      10\n",
      "unique       NaN                            10       3\n",
      "top          NaN  The product arrived damaged.      US\n",
      "freq         NaN                             1       4\n",
      "mean     5.50000                           NaN     NaN\n",
      "std      3.02765                           NaN     NaN\n",
      "min      1.00000                           NaN     NaN\n",
      "25%      3.25000                           NaN     NaN\n",
      "50%      5.50000                           NaN     NaN\n",
      "75%      7.75000                           NaN     NaN\n",
      "max     10.00000                           NaN     NaN\u001b[0m\u001b[32;1m\u001b[1;3mNow I can use the pandas calculator to count the rows.\n",
      "Action: pandas_calculator\n",
      "Action Input: {\"expr\": \"len(df[df['country'].str.contains('US')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}\u001b[0m-{\"expr\": \"len(df[df['country'].str.contains('US')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}-\n",
      "   index                                       comment country\n",
      "0      1                  The product arrived damaged.      US\n",
      "1      2              I'm very happy with the service!  Mexico\n",
      "2      3             I have a question about my order.  Canada\n",
      "3      4                        The delivery was late.      US\n",
      "4      5  The customer support agent was very helpful.  Canada\n",
      "5      6   I'm not satisfied with the product quality.  Mexico\n",
      "6      7                     I need to return an item.      US\n",
      "7      8                   The website is easy to use.      US\n",
      "8      9     I couldn't find the information I needed.  Canada\n",
      "9     10                        The price is too high.  Mexico\n",
      "\u001b[36;1m\u001b[1;3m4\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: There are 4 rows from the US.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[(AgentAction(tool='csv_summary_statistics', tool_input='{\"csv_input_file\": \"files/customer-comments-small.csv\"}', log='Thought: I can use the pandas_calculator tool to count the number of rows where the country is US. First I will check the summary statistics of the csv to understand the data better.\\nAction: csv_summary_statistics\\nAction Input: {\"csv_input_file\": \"files/customer-comments-small.csv\"}'), \"first few rows of data: \\n   index                                       comment country\\n0      1                  The product arrived damaged.      US\\n1      2              I'm very happy with the service!  Mexico\\n2      3             I have a question about my order.  Canada\\n3      4                        The delivery was late.      US\\n4      5  The customer support agent was very helpful.  Canada\\n\\ninformation on the data:            index                       comment country\\ncount   10.00000                            10      10\\nunique       NaN                            10       3\\ntop          NaN  The product arrived damaged.      US\\nfreq         NaN                             1       4\\nmean     5.50000                           NaN     NaN\\nstd      3.02765                           NaN     NaN\\nmin      1.00000                           NaN     NaN\\n25%      3.25000                           NaN     NaN\\n50%      5.50000                           NaN     NaN\\n75%      7.75000                           NaN     NaN\\nmax     10.00000                           NaN     NaN\"), (AgentAction(tool='pandas_calculator', tool_input='{\"expr\": \"len(df[df[\\'country\\'].str.contains(\\'US\\')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}', log='Now I can use the pandas calculator to count the rows.\\nAction: pandas_calculator\\nAction Input: {\"expr\": \"len(df[df[\\'country\\'].str.contains(\\'US\\')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}'), '4')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 4 rows from the US.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(CSV_FILE_SMALL + \" can you count how many rows are from the US?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8Yv3T5r8N9uR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5007,
     "status": "ok",
     "timestamp": 1730321954768,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "8Yv3T5r8N9uR",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5ad0ebd7-a8e4-44f8-af12-c03a76e825a2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: how many rows are positive and how many are negative sentiment?\n",
      "Thought: There is no sentiment column. I need to generate it first using the generate_column tool. Then I can use pandas_calculator to count.\n",
      "Action: generate_column\n",
      "Action Input: {\"csv_input_file\": \"files/customer-comments-small.csv\", \"prompt_instructions\": \"Classify the sentiment of the customer comment as either positive or negative.\\nCustomer comment: \", \"column_name\": \"sentiment\"}\u001b[0mrewrite prompt :For this specific row, classify the sentiment of the customer comment as one of the following: [positive, negative].\n",
      "\n",
      "\u001b[38;5;200m\u001b[1;3mfiles/modified_file_name.csv\u001b[0m\u001b[32;1m\u001b[1;3mNow I can use the pandas calculator to count the rows.\n",
      "Action: pandas_calculator\n",
      "Action Input: {\"expr\": \"len(df[df['sentiment'].str.contains('positive')]), len(df[df['sentiment'].str.contains('negative')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}\u001b[0m-{\"expr\": \"len(df[df['sentiment'].str.contains('positive')]), len(df[df['sentiment'].str.contains('negative')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}-\n",
      "   index                                       comment country sentiment\n",
      "0      1                  The product arrived damaged.      US  negative\n",
      "1      2              I'm very happy with the service!  Mexico  positive\n",
      "2      3             I have a question about my order.  Canada  negative\n",
      "3      4                        The delivery was late.      US  negative\n",
      "4      5  The customer support agent was very helpful.  Canada  positive\n",
      "5      6   I'm not satisfied with the product quality.  Mexico  negative\n",
      "6      7                     I need to return an item.      US  negative\n",
      "7      8                   The website is easy to use.      US  positive\n",
      "8      9     I couldn't find the information I needed.  Canada  negative\n",
      "9     10                        The price is too high.  Mexico  negative\n",
      "\u001b[36;1m\u001b[1;3m(3, 7)\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: There are 3 positive and 7 negative comments.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[(AgentAction(tool='generate_column', tool_input='{\"csv_input_file\": \"files/customer-comments-small.csv\", \"prompt_instructions\": \"Classify the sentiment of the customer comment as either positive or negative.\\\\nCustomer comment: \", \"column_name\": \"sentiment\"}', log='Question: how many rows are positive and how many are negative sentiment?\\nThought: There is no sentiment column. I need to generate it first using the generate_column tool. Then I can use pandas_calculator to count.\\nAction: generate_column\\nAction Input: {\"csv_input_file\": \"files/customer-comments-small.csv\", \"prompt_instructions\": \"Classify the sentiment of the customer comment as either positive or negative.\\\\nCustomer comment: \", \"column_name\": \"sentiment\"}'), 'files/modified_file_name.csv'), (AgentAction(tool='pandas_calculator', tool_input='{\"expr\": \"len(df[df[\\'sentiment\\'].str.contains(\\'positive\\')]), len(df[df[\\'sentiment\\'].str.contains(\\'negative\\')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}', log='Now I can use the pandas calculator to count the rows.\\nAction: pandas_calculator\\nAction Input: {\"expr\": \"len(df[df[\\'sentiment\\'].str.contains(\\'positive\\')]), len(df[df[\\'sentiment\\'].str.contains(\\'negative\\')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}'), '(3, 7)')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 3 positive and 7 negative comments.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(\"how many rows are positive and how many are negative sentiment?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf62bb-2a3a-4c30-b99e-7c7a6335053e",
   "metadata": {},
   "source": [
    "## Create UI for the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7592f475-335d-4c8d-9d9a-a68e8ede86cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b95bd7a542e436ca7c8e11d8488b2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af8e019be14487ab7c528643b093776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value='', layout=Layout(width='100%'), placeholder='Enter text here...'), Button(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "\n",
    "# Create text box for user input\n",
    "user_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter text here...',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Create output area for conversation display\n",
    "conversation_history = widgets.Output()\n",
    "display(conversation_history)\n",
    "\n",
    "# Create button for user to click to send their message\n",
    "send_button = widgets.Button(description='Send')\n",
    "\n",
    "def send_button_clicked(b):\n",
    "    with conversation_history:\n",
    "        # User message with gray bubble\n",
    "        user_message = f\"\"\"\n",
    "        <div style=\"display: flex; align-items: flex-start;\">\n",
    "            <div style=\"background-color: lightgray; padding: 10px; border-radius: 10px; margin-right: 10px;\">\n",
    "                {user_input.value}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(user_message))\n",
    "\n",
    "        # Get chatbot response\n",
    "        response = invoke(user_input.value)\n",
    "\n",
    "        # AI response with blue bubble\n",
    "        ai_message = f\"\"\"\n",
    "        <div style=\"display: flex; align-items: flex-start; justify-content: flex-end;\">\n",
    "            <div style=\"background-color: lightblue; padding: 10px; border-radius: 10px; margin-left: 10px;\">\n",
    "                {response}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(ai_message))\n",
    "\n",
    "        # Clear user input box\n",
    "        user_input.value = ''\n",
    "\n",
    "send_button.on_click(send_button_clicked)\n",
    "\n",
    "# Display the input box and send button\n",
    "display(widgets.HBox([user_input, send_button]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "csv_analyzer",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
