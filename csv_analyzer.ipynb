{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2mdBNzaq8XW2",
   "metadata": {
    "id": "2mdBNzaq8XW2"
   },
   "source": [
    "# Talk to Small CSV Data\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/felipecastrillon/FelipesGenAIExplorer/blob/main/csv_analyzer.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Ffelipecastrillon%2FFelipesGenAIExplorer%2Frefs%2Fheads%2Fmain%2Fcsv_analyzer.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/felipecastrillon/FelipesGenAIExplorer/blob/main/csv_analyzer.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/felipecastrillon/FelipesGenAIExplorer/refs/heads/main/csv_analyzer.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>    \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea575b2-3a61-43ae-9454-e515d4d377cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generative Question and Answer (QnA) analyzer of small csv files (100s or 1000s of rows) where traditionally users are doing analysis on a spreadsheet but want a more interactive way to do their analysis. \n",
    "\n",
    "Today you can drop a csv on your LLM of choice and can get decent answers to some language summarization tasks like topic categorization, sentiment analysis, sampling of data. Where LLM usually fail is in doing computation of your data i.e. filtering, aggregation, counts etc. \n",
    "\n",
    "In order to overcome this drawback we are taking advantage of an agentic approach while giving it access to a pandas runner. This allows the agent the ability to run computations via pandas commands. The agent will use a reAct framework to be able to think through the problem and access the pandas dataframe only when necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gncZnt8YwkTS",
   "metadata": {
    "id": "gncZnt8YwkTS"
   },
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nwtoa1WKsSlSj4VrqdEY8LId",
   "metadata": {
    "id": "Nwtoa1WKsSlSj4VrqdEY8LId",
    "tags": []
   },
   "source": [
    "Install the Langchain packages: Open a terminal window and enter the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qsskCvGUcbn34hNAWisBS4Uk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 46113,
     "status": "ok",
     "timestamp": 1730319297839,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "qsskCvGUcbn34hNAWisBS4Uk",
    "outputId": "fc4d3234-5fe5-44ea-8dba-f70683408d49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade google-cloud-aiplatform\n",
    "!pip install --quiet vertexai\n",
    "!pip install --quiet langchain-google-genai\n",
    "!pip install --quiet langchain\n",
    "!pip install --quiet langchain-experimental\n",
    "!pip install --no-deps --quiet langchain-google-vertexai \n",
    "!pip install --quiet panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9d81f-d79a-4bb1-bf65-f7f51245daa6",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4fd443a-f7fd-432d-a909-10e3513bcd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = 'felipe-sandbox-354619' # replace with project ID\n",
    "BUCKET = PROJECT + \"-bucket\" # make sure this bucket exists\n",
    "CSV_FILE_SMALL = \"files/customer-comments-small.csv\" \n",
    "CSV_FILE_MEDIUM = \"files/customer-comments.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce2df3-64a3-4f57-a9fb-1c8a1dfcc83b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Colab setup if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af014e5-b39e-4a93-9e0a-628717e83c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eefb1f-89cb-4231-8f57-75888dafa34c",
   "metadata": {},
   "source": [
    "## Naive Approach: Ask LLM Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e775bc-7b7a-4831-a9a2-f683eabf26b2",
   "metadata": {},
   "source": [
    "LLMs struggle at counting and providing analytics without any proper guidance. Let's look at an example for a file that has 100 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd31854f-6248-4865-b2e9-f5f0707e6d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "llm = ChatVertexAI(model=\"gemini-1.5-pro-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0511b6a6-d1a1-450c-9224-ddb0d161bf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def csv_to_string(filename):\n",
    "  \"\"\"\n",
    "  Reads a CSV file and returns its contents as a string.\n",
    "\n",
    "  Args:\n",
    "    filename: The path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "    A string containing the CSV data.\n",
    "  \"\"\"\n",
    "\n",
    "  df = pd.read_csv(CSV_FILE_MEDIUM).drop(\"index\", axis=1)\n",
    "  df =df.reset_index(drop=True)\n",
    "  return df.to_string(index=False)\n",
    "    \n",
    "    \n",
    "  with open(filename, 'r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = \"\"\n",
    "    for row in reader:\n",
    "      data += ','.join(row) + '\\n'  # Join row elements with commas and add newline\n",
    "    return data\n",
    "\n",
    "# Example usage \n",
    "csv_string_small = csv_to_string(CSV_FILE_SMALL)\n",
    "csv_string = csv_to_string(CSV_FILE_MEDIUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e7ac30-9e1e-461d-ac7b-85f3611af85f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 75 rows of comments and countries in the data you provided. Each line containing a comment and a country represents a row.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(csv_string + \"\\n how many rows in the file?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4243f0b-d898-4d0e-a7a7-6a0a4d591f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "\n",
      "34\n",
      "\n",
      "33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(csv_string + \"\\n how many rows from the US?, please be brief\").content)\n",
    "print(llm.invoke(csv_string + \"\\n how many rows from Canada?, please be brief\").content)\n",
    "print(llm.invoke(csv_string + \"\\n how many rows from Mexico?, please be brief\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c3e91-de93-47e1-b848-84612c5f0674",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "We run a query to get the actual results to see if our LLM generated answers are correct. As you can see our LLM answers are not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50d68e76-c286-44fe-96f1-5ff324a04de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_FILE_MEDIUM)\n",
    "print(len(df[df['country'].str.contains('US')]))\n",
    "print(len(df[df['country'].str.contains('Canada')]))\n",
    "print(len(df[df['country'].str.contains('Mexico')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3EZsamn67y6J",
   "metadata": {
    "id": "3EZsamn67y6J"
   },
   "source": [
    "## Building an Agent with Langchain and Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f585656-6fed-4696-bc03-e3fbe840ca42",
   "metadata": {},
   "source": [
    "In order to ovecome some of these obstacles we want to use a LLM method called a ReAct Agent where the LLM can think before answering. ReAct works by having a self-contained Tools that can help solve a task. These tools will focus on a specific task and are generally deterministic in natur like code, API calls. Note that they don't always have to be deterministic but can also be additional Generative AI calls focusing on one specific task.\n",
    "\n",
    "The ReAct Agent will then think about each step carefully to come up with a set of steps to solve the problem and also determine if one of the Tools will be needed to solve the taks. This allows a more robust process to solve difficult answers and leverage grounded steps within the Tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aZAoXfB8z4uIoOWQgYDPEvj5",
   "metadata": {
    "id": "aZAoXfB8z4uIoOWQgYDPEvj5",
    "tags": []
   },
   "source": [
    "### Create Agent Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6adc58-396f-4dae-84d5-134cdf74fc44",
   "metadata": {},
   "source": [
    "Create a computational tool via pandas dataframe to run analysis. Note that a limitation is that it will load a pandas dataframe everytime the tool is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dFDFBiEF-cX",
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1730321794859,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "2dFDFBiEF-cX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import tool\n",
    "from io import StringIO\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "@tool(\"pandas_calculator\", return_direct=False)\n",
    "def pandas_calculator(dictionary:str):\n",
    "    \"\"\"\n",
    "    Evaluates an expression on a Pandas DataFrame and returns the result.\n",
    "    Inputs include an expression expr and a file path csv_file_path\n",
    "    Inputs should be in format {\\\"expr\\\": str, \\\"csv_file_path\\\": str}\n",
    "    \n",
    "    Always favor df.contains functions instead of precise functions using equality operators\n",
    "    \"\"\"\n",
    "    print (\"-\" + dictionary + \"-\")\n",
    "    dictionary = json.loads(dictionary)\n",
    "    csv_file_path = dictionary[\"csv_file_path\"]\n",
    "    expr = dictionary[\"expr\"]\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(df)\n",
    "        # evaluate expr on the pandas dataframe\n",
    "        result = eval(expr)\n",
    "        # return the result\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Could not load data or evaluate expression. {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bcfd5a-168f-4b5a-8270-f92ac151b626",
   "metadata": {},
   "source": [
    "Tool to summarize the file so that LLM can generate correct SQLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6506fb-b152-456d-b4d9-724e9b42164f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-{\"csv_input_file\":\"files/customer-comments-small.csv\"}-\n",
      "first few rows of data: \n",
      "   index                                       comment country\n",
      "0      1                  The product arrived damaged.      US\n",
      "1      2              I'm very happy with the service!  Mexico\n",
      "2      3             I have a question about my order.  Canada\n",
      "3      4                        The delivery was late.      US\n",
      "4      5  The customer support agent was very helpful.  Canada\n",
      "\n",
      "information on the data:            index                       comment country\n",
      "count   10.00000                            10      10\n",
      "unique       NaN                            10       3\n",
      "top          NaN  The product arrived damaged.      US\n",
      "freq         NaN                             1       4\n",
      "mean     5.50000                           NaN     NaN\n",
      "std      3.02765                           NaN     NaN\n",
      "min      1.00000                           NaN     NaN\n",
      "25%      3.25000                           NaN     NaN\n",
      "50%      5.50000                           NaN     NaN\n",
      "75%      7.75000                           NaN     NaN\n",
      "max     10.00000                           NaN     NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2295/1280251748.py:25: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(csv_summary_statistics(test_path))\n"
     ]
    }
   ],
   "source": [
    "@tool(\"csv_summary_statistics\", return_direct=False)\n",
    "def csv_summary_statistics(dictionary:str):\n",
    "    \"\"\"\n",
    "    Gets summary statistics on the csv to understand the data\n",
    "    Before running pandas calculator please run the statistics first\n",
    "    Inputs should be in format: {\\\"csv_input_file\\\": str}\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"-\" + dictionary + \"-\")\n",
    "    dictionary = json.loads(dictionary)\n",
    "    input_path = dictionary[\"csv_input_file\"]\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "        # evaluate expr on the pandas dataframe\n",
    "        result = \"first few rows of data: \\n\" + df.head().to_string() + \"\\n\\n\"\n",
    "        result += \"information on the data: \" + df.describe(include='all').to_string()\n",
    "        #print(df.info())\n",
    "        # return the result\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Could not load data or evaluate expression. {e}\"\n",
    "    \n",
    "test_path = \"{\\\"csv_input_file\\\":\\\"\" + CSV_FILE_SMALL + \"\\\"}\"\n",
    "print(csv_summary_statistics(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ceeb5-88b0-4484-a4fb-63929b916c23",
   "metadata": {},
   "source": [
    "Create a tool that can fill columns using generative calls. Note that this tool will iterate through each row and will call the GenAI model for each row. This can take some time as every call can take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48fb4b7e-c655-4415-8442-06abeff4cdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewrite prompt :For this specific row, pick one of the following sentiment analysis categories: [Positive, Negative].\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'files/modified_file_name.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "@tool(\"generate_column\", return_direct=False)\n",
    "def generate_column(dictionary:str):\n",
    "    \"\"\"\n",
    "    For some tasks the column that is needed does not exist and needs to be generated via LLM\n",
    "    This function will loop through each row and fill in the column via some prompt instructions\n",
    "    Inputs should be in format {\\\"csv_input_file\\\": str, \"prompt_instructions\":str, \"column_name\":str}\n",
    "    \n",
    "    csv_input_file: is the file to be loaded\n",
    "    column_name: is the name of the new column that will be generated\n",
    "    prompt_instructions: is the prompt used by the LLM to generate the column. This will be applied to \n",
    "    each row based on function: df[column_name] = df.apply(lambda x: llm.generate(prompt_instructions + \"\\n row context\" + x + \"\\n result:\\n\"))\n",
    "    \"\"\"\n",
    "    \n",
    "    llm = ChatVertexAI(model=\"gemini-1.5-pro-002\")\n",
    "    \n",
    "    dictionary = json.loads(dictionary)\n",
    "    input_path = dictionary[\"csv_input_file\"]\n",
    "    prompt_instructions = dictionary[\"prompt_instructions\"]\n",
    "    column_name = dictionary[\"column_name\"]\n",
    "    \n",
    "    prompt_prefix = \"\"\"Follow the instructions, be to the point and do not do anything outside of the\n",
    "                    \"instructions. \n",
    "                    \n",
    "                    INSTRUCTIONS:\n",
    "                    answer should be concise\n",
    "                    answer should not have a newline character\n",
    "                    answer should not have any special characters\n",
    "                    \n",
    "                    \"\"\"\n",
    "\n",
    "    better_prompt_instructions = llm.invoke(f\"\"\"can you help me rewrite this prompt to a better more specific prompt\n",
    "                                            Each of these instructions will be applied to \"this row\" please specify that\n",
    "                                            if the answer needs be categorical please come up with the proper categories in brackets: i.e. [cat1, cat2]\n",
    "                                        \n",
    "                                            \n",
    "                                            EXAMPLE: \n",
    "                                            \n",
    "                                            PROMPT: does this refer to a cat or a dog\n",
    "                                            NEW PROMPT: for this specific row does this refer to one of the following categories [cat,dog] pick one as your answer\n",
    "                                            \n",
    "                                            Please only focus on the task of writing one specific prompt, do not provide any additional information or explanation\n",
    "                                            \n",
    "                                            PROMPT:\n",
    "                                            {prompt_instructions}\n",
    "                                            \n",
    "                                            NEW PROMPT:\"\"\").content\n",
    "    \n",
    "    print(\"rewrite prompt :\" + better_prompt_instructions)\n",
    "    \n",
    "    def generate_sentiment(row, prompt_instructions):\n",
    "        prompt = f\"{prompt_prefix} \\nINSTRUCTIONS: {better_prompt_instructions} \\nCONTEXT ROW: {row.to_string()} \\nANSWER:\"\n",
    "        #print(\"final prompt \" + prompt)\n",
    "        return llm.invoke(prompt).content  # Pass the message object to generate()\n",
    "        \n",
    "    df = pd.read_csv(input_path)\n",
    "    df[column_name] = df.apply(lambda x:generate_sentiment(x, prompt_instructions).strip(), axis=1)\n",
    "    filename = 'files/modified_file_name.csv'\n",
    "    df.to_csv(filename, index=False) \n",
    "\n",
    "    return filename\n",
    "\n",
    "data_test = '{\\\"csv_input_file\\\":\\\"'+CSV_FILE_SMALL+'\\\", \\\"prompt_instructions\\\":\\\"pick positive or negative sentiment analysis for each row\\\", \\\"column_name\\\":\\\"sentiment\\\"}'\n",
    "generate_column(data_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ff324-5368-4b4f-aef8-8d7547277279",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create the ReAct Agent using the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e7b7a4-bd5e-4c04-b310-272bf776269a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_string = \"\"\"\n",
    "Assistant is a large language model trained by OpenAI.\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "TOOLS:\n",
    "\n",
    "------\n",
    "\n",
    "Assistant has access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "```\n",
    "\n",
    "Sometimes if the questions does not require a tool you can answer like this:\n",
    "\n",
    "```\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "```\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "New input: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "n7YCgEQM74Ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1730321798695,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "n7YCgEQM74Ac",
    "outputId": "8a20b6d9-d9ab-4c39-edf1-69c024e49963",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.memory import ConversationBufferWindowMemory, ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-1.5-pro-002\", temperature=0)\n",
    "prompt = PromptTemplate.from_template(prompt_string)\n",
    "#prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "chat_history = ConversationBufferWindowMemory(k=10)\n",
    "\n",
    "agent = create_react_agent(llm, [pandas_calculator,csv_summary_statistics,generate_column], prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent,\n",
    "                               tools=[pandas_calculator,csv_summary_statistics,generate_column],\n",
    "                               verbose=True, handle_parsing_errors=True,\n",
    "                               max_iterations=5, return_intermediate_steps=True)\n",
    "\n",
    "def append_chat_history(input, response):\n",
    "    chat_history.save_context({\"input\": input}, {\"output\": response})\n",
    "\n",
    "def tuples_to_string(list_of_tuples):\n",
    "  \"\"\"Converts a list of tuples to a string representation.\"\"\"\n",
    "\n",
    "  # If the list is empty, return an empty string\n",
    "  if not list_of_tuples:\n",
    "    return \"\"\n",
    "\n",
    "  # Join the tuples with a newline character\n",
    "  string = \"\\n\".join([str(tup) for tup in list_of_tuples])\n",
    "  return string\n",
    "    \n",
    "def invoke(input):\n",
    "    if (input):\n",
    "        #print(\"input: \" + str(input))\n",
    "        msg = {\n",
    "            \"input\": input,\n",
    "            \"chat_history\": chat_history.load_memory_variables({}),\n",
    "        }\n",
    "        #print(f\"Input: {msg}\")\n",
    "\n",
    "        response = agent_executor.invoke(msg)\n",
    "        response[\"output\"] = response[\"output\"].split(\"\\n\")[0]\n",
    "        #print(f\"Response: {response}\")\n",
    "\n",
    "        if not response[\"intermediate_steps\"]:\n",
    "            response[\"intermediate_steps\"] = [\"NaN\"]\n",
    "        \n",
    "        print(response[\"intermediate_steps\"])\n",
    "        output_string = \"intermediate steps: \" + tuples_to_string(response[\"intermediate_steps\"]) + \" | response: \" + response[\"output\"]\n",
    "        append_chat_history(response[\"input\"], output_string)\n",
    "        #print(f\"History: {chat_history.load_memory_variables({})}\")\n",
    "\n",
    "        return response[\"output\"]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c0fadf-17ae-4072-b162-74150b8c8563",
   "metadata": {},
   "source": [
    "### Try Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d49d24b-2e63-45d2-ad00-ddcd142e8203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: Hi there! How can I help you today?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['NaN']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eVrNIXm9MHtm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3492,
     "status": "ok",
     "timestamp": 1730321808028,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "eVrNIXm9MHtm",
    "outputId": "caf99249-d308-4d8c-81fd-cba6a9fb7348",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: files/customer-comments-small.csv can you count how many rows are from the US?\n",
      "Thought: I can use the pandas_calculator tool to count the number of rows where the country is US. First I will use the csv_summary_statistics tool to check the data.\n",
      "Action: csv_summary_statistics\n",
      "Action Input: {\"csv_input_file\": \"files/customer-comments-small.csv\"}\u001b[0m-{\"csv_input_file\": \"files/customer-comments-small.csv\"}-\n",
      "\u001b[33;1m\u001b[1;3mfirst few rows of data: \n",
      "   index                                       comment country\n",
      "0      1                  The product arrived damaged.      US\n",
      "1      2              I'm very happy with the service!  Mexico\n",
      "2      3             I have a question about my order.  Canada\n",
      "3      4                        The delivery was late.      US\n",
      "4      5  The customer support agent was very helpful.  Canada\n",
      "\n",
      "information on the data:            index                       comment country\n",
      "count   10.00000                            10      10\n",
      "unique       NaN                            10       3\n",
      "top          NaN  The product arrived damaged.      US\n",
      "freq         NaN                             1       4\n",
      "mean     5.50000                           NaN     NaN\n",
      "std      3.02765                           NaN     NaN\n",
      "min      1.00000                           NaN     NaN\n",
      "25%      3.25000                           NaN     NaN\n",
      "50%      5.50000                           NaN     NaN\n",
      "75%      7.75000                           NaN     NaN\n",
      "max     10.00000                           NaN     NaN\u001b[0m\u001b[32;1m\u001b[1;3mNow I can use the pandas calculator to count the rows.\n",
      "Action: pandas_calculator\n",
      "Action Input: {\"expr\": \"len(df[df['country'].str.contains('US')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}\u001b[0m-{\"expr\": \"len(df[df['country'].str.contains('US')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}-\n",
      "   index                                       comment country\n",
      "0      1                  The product arrived damaged.      US\n",
      "1      2              I'm very happy with the service!  Mexico\n",
      "2      3             I have a question about my order.  Canada\n",
      "3      4                        The delivery was late.      US\n",
      "4      5  The customer support agent was very helpful.  Canada\n",
      "5      6   I'm not satisfied with the product quality.  Mexico\n",
      "6      7                     I need to return an item.      US\n",
      "7      8                   The website is easy to use.      US\n",
      "8      9     I couldn't find the information I needed.  Canada\n",
      "9     10                        The price is too high.  Mexico\n",
      "\u001b[36;1m\u001b[1;3m4\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: There are 4 rows from the US.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[(AgentAction(tool='csv_summary_statistics', tool_input='{\"csv_input_file\": \"files/customer-comments-small.csv\"}', log='Question: files/customer-comments-small.csv can you count how many rows are from the US?\\nThought: I can use the pandas_calculator tool to count the number of rows where the country is US. First I will use the csv_summary_statistics tool to check the data.\\nAction: csv_summary_statistics\\nAction Input: {\"csv_input_file\": \"files/customer-comments-small.csv\"}'), \"first few rows of data: \\n   index                                       comment country\\n0      1                  The product arrived damaged.      US\\n1      2              I'm very happy with the service!  Mexico\\n2      3             I have a question about my order.  Canada\\n3      4                        The delivery was late.      US\\n4      5  The customer support agent was very helpful.  Canada\\n\\ninformation on the data:            index                       comment country\\ncount   10.00000                            10      10\\nunique       NaN                            10       3\\ntop          NaN  The product arrived damaged.      US\\nfreq         NaN                             1       4\\nmean     5.50000                           NaN     NaN\\nstd      3.02765                           NaN     NaN\\nmin      1.00000                           NaN     NaN\\n25%      3.25000                           NaN     NaN\\n50%      5.50000                           NaN     NaN\\n75%      7.75000                           NaN     NaN\\nmax     10.00000                           NaN     NaN\"), (AgentAction(tool='pandas_calculator', tool_input='{\"expr\": \"len(df[df[\\'country\\'].str.contains(\\'US\\')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}', log='Now I can use the pandas calculator to count the rows.\\nAction: pandas_calculator\\nAction Input: {\"expr\": \"len(df[df[\\'country\\'].str.contains(\\'US\\')])\", \"csv_file_path\": \"files/customer-comments-small.csv\"}'), '4')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 4 rows from the US.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(CSV_FILE_SMALL + \" can you count how many rows are from the US?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8Yv3T5r8N9uR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5007,
     "status": "ok",
     "timestamp": 1730321954768,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "8Yv3T5r8N9uR",
    "outputId": "5ad0ebd7-a8e4-44f8-af12-c03a76e825a2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to create a new column called sentiment and then count how many are positive and negative.\n",
      "\n",
      "Action: generate_column\n",
      "Action Input: {\"csv_input_file\": \"files/customer-comments-small.csv\", \"prompt_instructions\": \"Classify the sentiment of the customer comment as either positive, negative, or neutral.\\n\\nComment: {comment}\\n\\nSentiment:\", \"column_name\": \"sentiment\"}\n",
      "\u001b[0mrewrite prompt :For this specific row, classify the sentiment of the customer comment as one of the following categories: [positive, negative, neutral].\n",
      "\n",
      "Comment: {comment}\n",
      "\n",
      "Sentiment:\n",
      "\n",
      "\u001b[38;5;200m\u001b[1;3mfiles/modified_file_name.csv\u001b[0m\u001b[32;1m\u001b[1;3mNow I can use the pandas calculator to count the number of positive and negative sentiment rows.\n",
      "\n",
      "Action: pandas_calculator\n",
      "Action Input: {\"expr\": \"len(df[df['sentiment'].str.contains('positive')]), len(df[df['sentiment'].str.contains('negative')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}\u001b[0m-{\"expr\": \"len(df[df['sentiment'].str.contains('positive')]), len(df[df['sentiment'].str.contains('negative')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}-\n",
      "   index                                       comment country sentiment\n",
      "0      1                  The product arrived damaged.      US  negative\n",
      "1      2              I'm very happy with the service!  Mexico  positive\n",
      "2      3             I have a question about my order.  Canada   neutral\n",
      "3      4                        The delivery was late.      US  negative\n",
      "4      5  The customer support agent was very helpful.  Canada  positive\n",
      "5      6   I'm not satisfied with the product quality.  Mexico  negative\n",
      "6      7                     I need to return an item.      US   neutral\n",
      "7      8                   The website is easy to use.      US  positive\n",
      "8      9     I couldn't find the information I needed.  Canada  negative\n",
      "9     10                        The price is too high.  Mexico  negative\n",
      "\u001b[36;1m\u001b[1;3m(3, 5)\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: There are 3 positive and 5 negative comments.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[(AgentAction(tool='generate_column', tool_input='{\"csv_input_file\": \"files/customer-comments-small.csv\", \"prompt_instructions\": \"Classify the sentiment of the customer comment as either positive, negative, or neutral.\\\\n\\\\nComment: {comment}\\\\n\\\\nSentiment:\", \"column_name\": \"sentiment\"}\\n', log='Thought: I need to create a new column called sentiment and then count how many are positive and negative.\\n\\nAction: generate_column\\nAction Input: {\"csv_input_file\": \"files/customer-comments-small.csv\", \"prompt_instructions\": \"Classify the sentiment of the customer comment as either positive, negative, or neutral.\\\\n\\\\nComment: {comment}\\\\n\\\\nSentiment:\", \"column_name\": \"sentiment\"}\\n'), 'files/modified_file_name.csv'), (AgentAction(tool='pandas_calculator', tool_input='{\"expr\": \"len(df[df[\\'sentiment\\'].str.contains(\\'positive\\')]), len(df[df[\\'sentiment\\'].str.contains(\\'negative\\')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}', log='Now I can use the pandas calculator to count the number of positive and negative sentiment rows.\\n\\nAction: pandas_calculator\\nAction Input: {\"expr\": \"len(df[df[\\'sentiment\\'].str.contains(\\'positive\\')]), len(df[df[\\'sentiment\\'].str.contains(\\'negative\\')])\", \"csv_file_path\": \"files/modified_file_name.csv\"}'), '(3, 5)')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 3 positive and 5 negative comments.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(\"how many rows are positive and how many are negative sentiment?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf62bb-2a3a-4c30-b99e-7c7a6335053e",
   "metadata": {},
   "source": [
    "## Create UI for the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7592f475-335d-4c8d-9d9a-a68e8ede86cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c4646025f04cf1878e70cee2330e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e079f11403457d961c928af2e64608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value='', layout=Layout(width='100%'), placeholder='Enter text here...'), Button(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "\n",
    "# Create text box for user input\n",
    "user_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter text here...',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Create output area for conversation display\n",
    "conversation_history = widgets.Output()\n",
    "display(conversation_history)\n",
    "\n",
    "# Create button for user to click to send their message\n",
    "send_button = widgets.Button(description='Send')\n",
    "\n",
    "def send_button_clicked(b):\n",
    "    with conversation_history:\n",
    "        # User message with gray bubble\n",
    "        user_message = f\"\"\"\n",
    "        <div style=\"display: flex; align-items: flex-start;\">\n",
    "            <div style=\"background-color: lightgray; padding: 10px; border-radius: 10px; margin-right: 10px;\">\n",
    "                {user_input.value}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(user_message))\n",
    "\n",
    "        # Get chatbot response\n",
    "        response = invoke(user_input.value)\n",
    "\n",
    "        # AI response with blue bubble\n",
    "        ai_message = f\"\"\"\n",
    "        <div style=\"display: flex; align-items: flex-start; justify-content: flex-end;\">\n",
    "            <div style=\"background-color: lightblue; padding: 10px; border-radius: 10px; margin-left: 10px;\">\n",
    "                {response}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(ai_message))\n",
    "\n",
    "        # Clear user input box\n",
    "        user_input.value = ''\n",
    "\n",
    "send_button.on_click(send_button_clicked)\n",
    "\n",
    "# Display the input box and send button\n",
    "display(widgets.HBox([user_input, send_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4702d-1b6a-4576-b417-5e9d73241311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "csv_analyzer",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
